import streamlit as st
import feedparser
import trafilatura
from groq import Groq
import concurrent.futures
import json
import os
import socket
import requests
from datetime import datetime

# ==========================================
# 0. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… (V13.0 - Mega Sources Edition)
# ==========================================
SYSTEM_VERSION = "V13.0_MEGA_CLEAN" 
st.set_page_config(page_title="ÙŠÙ‚ÙŠÙ† AI - Ø§Ù„Ù…Ù†ØµØ© Ø§Ù„Ø´Ø§Ù…Ù„Ø©", page_icon="ğŸ—ï¸", layout="wide")
socket.setdefaulttimeout(20) # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ù‡Ù„Ø© Ø¨Ø³Ø¨Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØµØ§Ø¯Ø±
DB_FILE = "news_db_v13.json"

# ==========================================
# 1. Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°ÙƒÙŠ (3 ØµØ¨Ø§Ø­Ø§Ù‹)
# ==========================================
def auto_purge_at_3am():
    now = datetime.now()
    if now.hour == 3:
        if os.path.exists(DB_FILE):
            try:
                os.remove(DB_FILE)
                st.cache_data.clear()
            except: pass

auto_purge_at_3am()

# ==========================================
# 2. Ø§Ù„Ù…ØµØ§Ø¯Ø± (Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙˆØ³Ø¹Ø© - +20 Ù…ØµØ¯Ø± Ø¬Ø¯ÙŠØ¯)
# ==========================================
RSS_SOURCES = {
    "Ø§Ù„ØµØ­Ø§ÙØ© Ø§Ù„ÙˆØ·Ù†ÙŠØ© ğŸ‡²ğŸ‡¦": {
        "Ù‡Ø³Ø¨Ø±ÙŠØ³": "https://www.hespress.com/feed",
        "Ø´ÙˆÙ ØªÙŠÙÙŠ": "https://chouftv.ma/feed",
        "Ø§Ù„Ø¹Ù…Ù‚ Ø§Ù„Ù…ØºØ±Ø¨ÙŠ": "https://al3omk.com/feed",
        "Ø²Ù†Ù‚Ø© 20": "https://www.rue20.com/feed",
        "Ù‡Ø¨Ø© Ø¨Ø±ÙŠØ³": "https://ar.hibapress.com/feed",
        "Ø§Ù„ÙŠÙˆÙ… 24": "https://alyaoum24.com/feed",
        "ÙƒÙˆØ¯": "https://www.goud.ma/feed",
        "Ø¨Ø±Ù„Ù…Ø§Ù†.ÙƒÙˆÙ…": "https://www.barlamane.com/feed",
        "Ø§Ù„ØµØ¨Ø§Ø­": "https://assabah.ma/feed",
        "Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ù…ØºØ±Ø¨ÙŠØ©": "https://ahdath.info/feed",
        "ØªÙ„ÙŠÙƒØ³Ø¨Ø±ÙŠØ³": "https://telexpresse.com/feed",
        "Le360": "https://ar.le360.ma/rss",
        "ÙØ¨Ø±Ø§ÙŠØ±": "https://www.febrayer.com/feed",
        "Ø¢Ø´ÙƒØ§ÙŠÙ†": "https://achkayen.com/feed",
        "Ù…Ù…Ù„ÙƒØªÙ†Ø§": "https://mamlakatuna.ma/feed",
        "Ø§Ù„Ø¬Ø±ÙŠØ¯Ø© 24": "https://aljarida24.ma/feed",
        "Ù„ÙƒÙ…": "https://lakome2.com/feed",
        "Ø¹Ø¨Ø±": "https://aabbir.com/feed",
        "Ø³ÙÙŠØ±ÙƒÙ…": "https://safir24.com/feed",
        "Ø¨Ø§Ù†Ø§ØµØ§": "https://banassa.com/feed"
    },
    "Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø´Ù…Ø§Ù„ ÙˆØ§Ù„Ø¬Ù‡Ø§Øª ğŸŒŠ": {
        "Ø´Ù…Ø§Ù„ Ø¨ÙˆØ³Øª": "https://chamalpost.net/feed",
        "Ø¨Ø±ÙŠØ³ ØªØ·ÙˆØ§Ù†": "https://presstetouan.com/feed",
        "Ø·Ù†Ø¬Ø© 24": "https://tanja24.com/feed",
        "ØªØ·ÙˆØ§Ù† Ø¨Ø±ÙŠØ³": "https://tetouanpress.ma/feed",
        "Ø·Ù†Ø¬Ø© Ù†ÙŠÙˆØ²": "https://tanjanews.com/feed",
        "ÙƒØ§Ø¨ 24": "https://cap24.tv/feed",
        "ØµØ¯Ù‰ ØªØ·ÙˆØ§Ù†": "https://sadatetouan.com/feed",
        "Ø£ÙƒØ§Ø¯ÙŠØ± 24": "https://agadir24.info/feed",
        "Ù…Ø±Ø§ÙƒØ´ Ø§Ù„Ø¢Ù†": "https://www.marrakechalaan.com/feed",
        "Ù‡Ø³Ø¨Ø±ÙŠØ³ Ø¬Ù‡Ø§Øª": "https://www.hespress.com/regions/feed"
    },
    "Ø£Ø®Ø¨Ø§Ø± Ø¯ÙˆÙ„ÙŠØ© ÙˆØ§Ù‚ØªØµØ§Ø¯ ğŸŒ": {
        "Ø³ÙƒØ§ÙŠ Ù†ÙŠÙˆØ² Ø¹Ø±Ø¨ÙŠØ©": "https://www.skynewsarabia.com/rss/v1/middle-east.xml",
        "Ø§Ù„Ø¬Ø²ÙŠØ±Ø© Ù†Øª": "https://www.aljazeera.net/alritem/rss/rss.xml",
        "ÙØ±Ø§Ù†Ø³ 24": "https://www.france24.com/ar/rss",
        "BBC Ø¹Ø±Ø¨ÙŠ": "https://www.bbc.com/arabic/index.xml",
        "Ø§Ù‚ØªØµØ§Ø¯ÙƒÙ…": "https://www.economistcom.ma/feed",
        "Ø§Ù„Ù…ØµØ¯Ø± Ù…ÙŠØ¯ÙŠØ§": "https://almasdar.ma/feed",
        "Investing (Ø§Ù‚ØªØµØ§Ø¯)": "https://sa.investing.com/rss/news.rss"
    },
    "ÙÙ†ØŒ Ù…Ø´Ø§Ù‡ÙŠØ± ÙˆØ±ÙŠØ§Ø¶Ø© âš½": {
        "Ø§Ù„Ø¨Ø·ÙˆÙ„Ø©": "https://www.elbotola.com/rss",
        "Ù‡Ø³Ø¨Ø±ÙŠØ³ Ø±ÙŠØ§Ø¶Ø©": "https://hesport.com/feed",
        "Ø§Ù„Ù…Ù†ØªØ®Ø¨": "https://almountakhab.com/rss",
        "Ù„Ø§Ù„Ø© Ù…ÙˆÙ„Ø§ØªÙŠ": "https://www.lallamoulati.ma/feed/",
        "Ø³Ù„Ø·Ø§Ù†Ø©": "https://soltana.ma/feed",
        "ØºØ§Ù„ÙŠØ©": "https://ghalia.ma/feed",
        "Ù‡Ø§ÙŠ ÙƒÙˆØ±Ø©": "https://hihi2.com/feed"
    }
}

# ==========================================
# 3. CSS (ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø§Ù†Ø¯Ø¬Ø± Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ©)
# ==========================================
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;600;800&display=swap');
    html, body, [class*="st-"] { font-family: 'Cairo', sans-serif; text-align: right; }
    .brand-header {
        text-align: center; background: linear-gradient(135deg, #0f172a 0%, #1e3a8a 100%);
        color: white; padding: 2.5rem; border-radius: 15px; margin-bottom: 2rem;
    }
    .article-output {
        white-space: pre-wrap; background-color: #ffffff; color: #111; padding: 30px; 
        border-radius: 12px; border: 1px solid #cfd8dc; line-height: 2; font-size: 1.15rem;
        box-shadow: 0 10px 15px -3px rgba(0,0,0,0.1);
    }
    .stButton>button { background: #1e3a8a; color: white; border-radius: 10px; height: 3.5rem; width: 100%; font-weight: bold;}
</style>
""", unsafe_allow_html=True)

# ==========================================
# 4. Ù…Ø­Ø±Ùƒ Ø§Ù„ØµÙŠØ§ØºØ© Ø§Ù„Ù†Ø¸ÙŠÙØ© (Strict SEO & No Markdown)
# ==========================================
try:
    client = Groq(api_key=st.secrets["GROQ_API_KEY"])
except: client = None

def rewrite_mega_pro(text, tone, instr):
    if not client: return "Ø®Ø·Ø£: Ù…ÙØªØ§Ø­ GROQ Ù…ÙÙ‚ÙˆØ¯ ÙÙŠ Secrets"
    
    prompt = f"""
    Ø£Ù†Øª Ø±Ø¦ÙŠØ³ ØªØ­Ø±ÙŠØ± Ø®Ø¨ÙŠØ± ÙÙŠ SEO. Ø­ÙˆÙ‘Ù„ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ø¥Ù„Ù‰ Ù…Ù‚Ø§Ù„ ØµØ­ÙÙŠ Ù…ØªÙƒØ§Ù…Ù„.
    
    Ø§Ù„Ù‚ÙŠÙˆØ¯ Ø§Ù„ÙÙ†ÙŠØ© ÙˆØ§Ù„Ù„ØºÙˆÙŠØ© (Ù‡Ø§Ù… Ø¬Ø¯Ø§Ù‹):
    1. Ù…Ù…Ù†ÙˆØ¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø±Ù…ÙˆØ² Markdown Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹ (Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… ## Ø£Ùˆ ** Ø£Ùˆ * Ø£Ùˆ -).
    2. Ø§Ù„ØªÙ†Ø³ÙŠÙ‚: Ø§ÙƒØªØ¨ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† ÙÙŠ Ø£Ø³Ø·Ø± Ù…Ø³ØªÙ‚Ù„Ø© Ø¨Ø¯ÙˆÙ† Ø±Ù…ÙˆØ²ØŒ ÙˆØ§Ø³ØªØ®Ø¯Ù… Ø³Ø·Ø± ÙØ§Ø±Øº Ø¨ÙŠÙ† Ø§Ù„ÙÙ‚Ø±Ø§Øª.
    3. Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ (Yoast SEO): 
       - Ø§Ø³ØªØ®Ø¯Ù… "Ø§Ù„Ù…Ø¨Ù†ÙŠ Ù„Ù„Ù…Ø¹Ù„ÙˆÙ…" (Active Voice) Ø¨Ù†Ø³Ø¨Ø© 95%. (Ù…Ø«Ø§Ù„: 'Ù‚Ø±Ø±Øª Ø§Ù„Ø´Ø±ÙƒØ©' Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† 'ØªÙ… Ø§Ù„Ù‚Ø±Ø§Ø±').
       - Ø§Ù„Ø¬Ù…Ù„ Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹ (Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 18 ÙƒÙ„Ù…Ø© Ù„ÙƒÙ„ Ø¬Ù…Ù„Ø©).
       - Ø§Ù„ÙÙ‚Ø±Ø§Øª Ù‚ØµÙŠØ±Ø© (Ù„Ø§ ØªØ²ÙŠØ¯ Ø¹Ù† 3 Ø£Ø³Ø·Ø±).
       - Ø§Ø¯Ù…Ø¬ ÙƒÙ„Ù…Ø§Øª Ø§Ù†ØªÙ‚Ø§Ù„ Ù‚ÙˆÙŠØ© (Ø¹Ù„Ø§ÙˆØ© Ø¹Ù„Ù‰ Ø°Ù„ÙƒØŒ ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„ØŒ ÙˆÙ…Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…Ù†Ø·Ù„Ù‚).
    
    Ø§Ù„Ù‡ÙŠÙƒÙ„: Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ù‚Ø§Ù„ØŒ Ø«Ù… Ù…Ù‚Ø¯Ù…Ø© Ù‚ÙˆÙŠØ©ØŒ Ø«Ù… ÙÙ‚Ø±Ø§Øª Ù…Ù‚Ø³Ù…Ø© Ø¨Ø¹Ù†Ø§ÙˆÙŠÙ† Ù†ØµÙŠØ© Ø¹Ø§Ø¯ÙŠØ©.
    Ø§Ù„Ø£Ø³Ù„ÙˆØ¨: {tone}. Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: {instr}.
    
    Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ:
    {text[:3800]}
    """
    
    try:
        res = client.chat.completions.create(
            messages=[{"role": "user", "content": prompt}],
            model="llama-3.3-70b-versatile", temperature=0.3
        )
        return res.choices[0].message.content
    except Exception as e: return f"Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ: {str(e)}"

# ==========================================
# 5. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ÙˆØ§Ù„Ù…Ù†Ø·Ù‚
# ==========================================
st.markdown("<div class='brand-header'><h1>ÙŠÙ‚ÙŠÙ† AI - Ø§Ù„Ù…Ø­Ø±Ø± Ø§Ù„Ù…Ù„ÙŠØ§Ø±Ø¯ÙŠ</h1><p>Ø£ÙƒØ«Ø± Ù…Ù† 45 Ù…ØµØ¯Ø±Ø§Ù‹ Ø¥Ø®Ø¨Ø§Ø±ÙŠØ§Ù‹ ÙˆØµÙŠØ§ØºØ© Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ø¨Ù†Ù‚Ø±Ø© ÙˆØ§Ø­Ø¯Ø©</p></div>", unsafe_allow_html=True)

def fetch_items(name, url):
    try:
        d = feedparser.parse(url)
        return [{"title": e.title, "link": e.link, "source": name} for e in d.entries[:10]]
    except: return []

if os.path.exists(DB_FILE):
    with open(DB_FILE, 'r', encoding='utf-8') as f: db = json.load(f)
else: db = {"data": {}}

tabs = st.tabs(list(RSS_SOURCES.keys()))
for i, cat in enumerate(list(RSS_SOURCES.keys())):
    with tabs[i]:
        col_up, col_sel = st.columns([1, 4])
        with col_up:
            if st.button(f"ğŸ”„ ØªØ­Ø¯ÙŠØ« {cat}", key=f"btn_{i}"):
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ù…Ø³Ø­ Ø§Ù„Ù…ØµØ§Ø¯Ø±..."):
                    all_news = []
                    with concurrent.futures.ThreadPoolExecutor(max_workers=15) as exec:
                        futures = [exec.submit(fetch_items, n, u) for n, u in RSS_SOURCES[cat].items()]
                        for f in concurrent.futures.as_completed(futures): all_news.extend(f.result())
                    db["data"][cat] = all_news
                    with open(DB_FILE, 'w', encoding='utf-8') as f: json.dump(db, f, ensure_ascii=False)
                st.rerun()

        if cat in db["data"] and db["data"][cat]:
            news = db["data"][cat]
            choice = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ù…Ù‚Ø§Ù„:", range(len(news)), format_func=lambda x: f"[{news[x]['source']}] {news[x]['title']}", key=f"sb_{i}")
            
            c1, c2 = st.columns(2)
            with c1: tone = st.selectbox("Ø§Ù„Ù†Ø¨Ø±Ø©:", ["Ø¥Ø®Ø¨Ø§Ø±ÙŠ Ø±ØµÙŠÙ†", "ØªØ­Ù„ÙŠÙ„ÙŠ Ø¹Ù…ÙŠÙ‚", "ØªÙØ§Ø¹Ù„ÙŠ Ø³Ø±ÙŠØ¹"], key=f"tn_{i}")
            with c2: instr = st.text_input("Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© (SEO):", key=f"kw_{i}")

            if st.button("ğŸš€ Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ", key=f"go_{i}"):
                with st.status("ğŸ—ï¸ Ø¬Ø§Ø±ÙŠ Ø³Ø­Ø¨ Ø§Ù„Ù†Øµ ÙˆÙ…Ø¹Ø§Ù„Ø¬ØªÙ‡ Ù„ØºÙˆÙŠØ§Ù‹...", expanded=True):
                    raw = trafilatura.fetch_url(news[choice]['link'])
                    txt = trafilatura.extract(raw)
                    if txt:
                        final = rewrite_mega_pro(txt, tone, instr)
                        st.markdown("### âœ… Ø§Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù…Ù†Ø³Ù‚")
                        st.markdown(f"<div class='article-output'>{final}</div>", unsafe_allow_html=True)
                        st.text_area("Ù†Øµ Ø¬Ø§Ù‡Ø² Ù„Ù„Ù†Ø³Ø® Ø§Ù„Ù…Ø¨Ø§Ø´Ø±:", final, height=400)
                    else: st.error("Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù‡Ø°Ø§ Ø§Ù„Ù…ØµØ¯Ø± ÙŠÙ…Ù†Ø¹ Ø³Ø­Ø¨ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¢Ù„ÙŠØ§Ù‹.")
        else:
            st.info("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± Ø§Ù„ØªØ­Ø¯ÙŠØ« Ù„Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±.")

st.markdown("---")
st.caption("Ù†Ø¸Ø§Ù… ÙŠÙ‚ÙŠÙ† V13.0 - Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø§Ù†Ø¯Ø¬Ø± 2026 - Ù‚ÙˆØ© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙÙŠ Ø®Ø¯Ù…Ø© Ø§Ù„ØµØ­Ø§ÙØ©.")
