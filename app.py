import streamlit as st
import feedparser
import trafilatura
from groq import Groq
import concurrent.futures
import json
import os
import time
import threading
from datetime import datetime
import pytz

# ==========================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
# ==========================================
st.set_page_config(
    page_title="ÙˆÙƒÙŠÙ„ ÙŠÙ‚ÙŠÙ† - Ø§Ù„Ø·ÙŠØ§Ø± Ø§Ù„Ø¢Ù„ÙŠ",
    page_icon="ğŸ¦…",
    layout="wide"
)

DB_FILE = "news_db.json"

# ==========================================
# 2. CSS (Ø§Ù„ØªØµÙ…ÙŠÙ… Ø§Ù„Ù…Ø³ØªÙ‚Ø±)
# ==========================================
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;600;800&display=swap');
    * { font-family: 'Cairo', sans-serif !important; }
    h1, h2, h3, h4, h5, h6, .stMarkdown, .stText, p { text-align: right !important; }
    .stTextInput input, .stTextArea textarea, .stSelectbox div[data-baseweb="select"] { direction: rtl; text-align: right; }
    .news-card { background: #fff; padding: 15px; border-radius: 8px; margin-bottom: 10px; text-align: right; direction: rtl; border: 1px solid #eee; }
    .seo-result { background: #f0fdf4; border-right: 4px solid #16a34a; padding: 20px; border-radius: 8px; text-align: right; direction: rtl; }
    #MainMenu {visibility: hidden;} footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# ==========================================
# 3. Ø§Ù„Ù…ØµØ§Ø¯Ø±
# ==========================================
RSS_SOURCES = {
    "Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø´Ù…Ø§Ù„": {
        "Ø´Ù…Ø§Ù„ Ø¨ÙˆØ³Øª": "https://chamalpost.net/feed",
        "Ø¨Ø±ÙŠØ³ ØªØ·ÙˆØ§Ù†": "https://presstetouan.com/feed",
        "Ø·Ù†Ø¬Ø© 24": "https://tanja24.com/feed",
        "ØªØ·ÙˆØ§Ù† Ø¨Ø±ÙŠØ³": "https://tetouanpress.ma/feed",
        "ÙƒØ§Ø¨ 24": "https://cap24.tv/feed",
    },
    "ØµØ­Ù ÙˆØ·Ù†ÙŠØ©": {
        "Ù‡Ø³Ø¨Ø±ÙŠØ³": "https://www.hespress.com/feed",
        "Ø§Ù„Ø¹Ù…Ù‚": "https://al3omk.com/feed",
        "Ù…Ø¯Ø§Ø± 21": "https://madar21.com/feed",
        "ÙƒÙˆØ¯": "https://www.goud.ma/feed",
        "Ø§Ù„ØµØ¨Ø§Ø­": "https://assabah.ma/feed",
    },
    "Ø±ÙŠØ§Ø¶Ø©": {
        "Ø§Ù„Ø¨Ø·ÙˆÙ„Ø©": "https://www.elbotola.com/rss",
        "Ù‡Ø³Ø¨Ø±ÙŠØ³ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ©": "https://hesport.com/feed",
    }
}

# ==========================================
# 4. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø®Ù„ÙÙŠ (Backend Logic)
# ==========================================
try:
    if "GROQ_API_KEY" in st.secrets:
        client = Groq(api_key=st.secrets["GROQ_API_KEY"])
    else:
        st.warning("âš ï¸ Ù…ÙØªØ§Ø­ Groq Ù…ÙÙ‚ÙˆØ¯")
        client = None
except: client = None

def fetch_single_feed(source_name, url, limit):
    entries = []
    try:
        d = feedparser.parse(url)
        for e in d.entries[:limit]:
            entries.append({
                "title": e.title,
                "link": e.link,
                "source": source_name,
                "published": e.get("published", str(datetime.now()))
            })
    except: pass
    return entries

def update_database_logic():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙŠ ØªÙ‚ÙˆÙ… Ø¨Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø´Ø§Ù‚"""
    print(f"[{datetime.now()}] Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø®Ù„ÙÙŠ...")
    all_data = {}
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        for category, feeds in RSS_SOURCES.items():
            cat_items = []
            futures = [executor.submit(fetch_single_feed, src, url, 15) for src, url in feeds.items()]
            for f in concurrent.futures.as_completed(futures):
                cat_items.extend(f.result())
            all_data[category] = cat_items
            
    db_content = {
        "last_updated": datetime.now().timestamp(),
        "data": all_data
    }
    # Ø§Ù„ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø°Ø±ÙŠØ© Ù„ØªØ¬Ù†Ø¨ ØªÙ„Ù Ø§Ù„Ù…Ù„Ù
    temp_file = DB_FILE + ".tmp"
    with open(temp_file, 'w', encoding='utf-8') as f:
        json.dump(db_content, f, ensure_ascii=False)
    os.replace(temp_file, DB_FILE)
    print(f"[{datetime.now()}] ØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ« ÙˆØ­ÙØ¸ Ø§Ù„Ù…Ù„Ù.")

# --- Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ© (Background Scheduler) ---
@st.cache_resource
def start_background_worker():
    """Ù‡Ø°Ø§ Ø§Ù„Ø¹Ø§Ù…Ù„ ÙŠØ¹Ù…Ù„ ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ© Ù„Ù„Ø£Ø¨Ø¯ ÙˆÙ„Ø§ ÙŠØªÙˆÙ‚Ù"""
    def worker_loop():
        while True:
            try:
                # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„Ù
                if os.path.exists(DB_FILE):
                    with open(DB_FILE, 'r', encoding='utf-8') as f:
                        db = json.load(f)
                    last_ts = db.get('last_updated', 0)
                else:
                    last_ts = 0

                now = datetime.now()
                last_time = datetime.fromtimestamp(last_ts)
                
                # ØªÙˆÙ‚ÙŠØª Ø§Ù„Ù…ØºØ±Ø¨ Ù„Ù„ØªÙ†Ø¸ÙŠÙ
                tz_ma = pytz.timezone('Africa/Casablanca')
                now_ma = datetime.now(tz_ma)

                # Ø´Ø±Ø· 1: Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ø§Ø¹Ø© 2:30 ØµØ¨Ø§Ø­Ø§Ù‹
                if now_ma.hour == 2 and 30 <= now_ma.minute <= 35:
                    if os.path.exists(DB_FILE):
                        os.remove(DB_FILE)
                        print("ğŸ§¹ ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø±Ø´ÙŠÙ Ø§Ù„ÙŠÙˆÙ…ÙŠ.")
                        # Ù†Ù†ØªØ¸Ø± Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ø­ØªÙ‰ Ù„Ø§ ÙŠÙƒØ±Ø± Ø§Ù„Ø­Ø°Ù ÙÙŠ Ù†ÙØ³ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©
                        time.sleep(400) 
                        continue

                # Ø´Ø±Ø· 2: Ø§Ù„ØªØ­Ø¯ÙŠØ« ÙƒÙ„ Ø³Ø§Ø¹Ø©
                diff = now - last_time
                if diff.total_seconds() > 3600 or last_ts == 0:
                    update_database_logic()
                
                # Ù†Ù†Ø§Ù… Ø¯Ù‚ÙŠÙ‚Ø© Ù‚Ø¨Ù„ Ø§Ù„ÙØ­Øµ Ø§Ù„ØªØ§Ù„ÙŠ
                time.sleep(60)
                
            except Exception as e:
                print(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¹Ø§Ù…Ù„ Ø§Ù„Ø®Ù„ÙÙŠ: {e}")
                time.sleep(60)

    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®ÙŠØ· ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©
    t = threading.Thread(target=worker_loop, daemon=True)
    t.start()
    return t

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¹Ø§Ù…Ù„ Ø§Ù„Ø®Ù„ÙÙŠ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·
start_background_worker()

# ==========================================
# 5. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© (Frontend)
# ==========================================
def get_text(url):
    try:
        d = trafilatura.fetch_url(url)
        return trafilatura.extract(d) if d else None
    except: return None

def rewrite(text, tone, instr):
    if not client: return "Ø®Ø·Ø£: Ø§Ù„Ù…ÙØªØ§Ø­ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"
    prompt = f"""
    Ø£Ù†Øª Ù…Ø­Ø±Ø± ØµØ­ÙÙŠ. Ø£Ø¹Ø¯ ØµÙŠØ§ØºØ© Ù‡Ø°Ø§ Ø§Ù„Ø®Ø¨Ø± Ù„Ù€ "Ù‡Ø§Ø´Ù…ÙŠ Ø¨Ø±ÙŠØ³".
    Ø§Ù„Ù†Øµ: {text[:2500]}
    Ø§Ù„Ø£Ø³Ù„ÙˆØ¨: {tone}. Ù…Ù„Ø§Ø­Ø¸Ø§Øª: {instr}.
    Ø§Ù„Ø¹Ù†ÙˆØ§Ù† H1 Ø¬Ø°Ø§Ø¨.
    """
    try:
        res = client.chat.completions.create(
            messages=[{"role": "user", "content": prompt}],
            model="llama-3.3-70b-versatile",
            temperature=0.7
        )
        return res.choices[0].message.content
    except Exception as e: return str(e)

st.title("ğŸ¦… ÙˆÙƒÙŠÙ„ ÙŠÙ‚ÙŠÙ† - Ø§Ù„Ø£Ø±Ø´ÙŠÙ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ")

# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¹Ø±Ø¶
if os.path.exists(DB_FILE):
    with open(DB_FILE, 'r', encoding='utf-8') as f:
        db = json.load(f)
    
    last_up = datetime.fromtimestamp(db['last_updated']).strftime('%H:%M')
    st.caption(f"ğŸ“… Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« Ù„Ù„Ù†Ø¸Ø§Ù…: {last_up} (ÙŠØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ« ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ ÙƒÙ„ Ø³Ø§Ø¹Ø©)")
    
    with st.sidebar:
        st.header("Ø§Ù„ØªØ­ÙƒÙ…")
        cat = st.selectbox("Ø§Ù„Ù‚Ø³Ù…", list(db['data'].keys()))
        news_list = db['data'][cat]
        tone = st.select_slider("Ø§Ù„Ù†Ø¨Ø±Ø©", ["Ø±Ø³Ù…ÙŠ", "ØªØ­Ù„ÙŠÙ„ÙŠ", "ØªÙØ§Ø¹Ù„ÙŠ"])
        ins = st.text_input("ØªÙˆØ¬ÙŠÙ‡Ø§Øª")
        if st.button("ØªØ­Ø¯ÙŠØ« ÙŠØ¯ÙˆÙŠ Ù‚Ø³Ø±ÙŠ"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ø¯ÙŠØ«..."):
                update_database_logic()
            st.rerun()

    # Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±
    opts = [f"ã€{n['source']}ã€‘ {n['title']}" for n in news_list]
    idx = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø®Ø¨Ø±:", range(len(opts)), format_func=lambda x: opts[x])
    
    if st.button("âœ¨ ØµÙŠØ§ØºØ©"):
        sel = news_list[idx]
        with st.status("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¹Ù…Ù„..."):
            txt = get_text(sel['link'])
            if txt:
                res = rewrite(txt, tone, ins)
                col1, col2 = st.columns(2)
                col1.info("Ø§Ù„Ø£ØµÙ„"); col1.markdown(f"<div class='news-card'>{txt[:500]}...</div>", unsafe_allow_html=True)
                col2.success("Ø§Ù„Ù†ØªÙŠØ¬Ø©"); col2.markdown(f"<div class='seo-result'>{res}</div>", unsafe_allow_html=True)
                st.download_button("ØªØ­Ù…ÙŠÙ„", res, "art.txt")
            else: st.error("Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ù…Ø­Ù…ÙŠ")

else:
    st.warning("â³ Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠÙ‚ÙˆÙ… Ø¨Ø§Ù„ØªÙ…Ù‡ÙŠØ¯ Ø§Ù„Ø£ÙˆÙ„ÙŠ ÙˆØ¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±... ÙŠØ±Ø¬Ù‰ ØªØ­Ø¯ÙŠØ« Ø§Ù„ØµÙØ­Ø© Ø¨Ø¹Ø¯ Ø¯Ù‚ÙŠÙ‚Ø©.")
    # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ Ù…Ù„ÙØŒ Ø§Ù„Ø¹Ø§Ù…Ù„ Ø§Ù„Ø®Ù„ÙÙŠ Ø³ÙŠÙ‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¦Ù‡ Ù‚Ø±ÙŠØ¨Ø§Ù‹
