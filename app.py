import streamlit as st
import feedparser
import trafilatura
from groq import Groq
import concurrent.futures
import json
import os
import socket
import requests
from datetime import datetime

# ==========================================
# 0. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
# ==========================================
SYSTEM_VERSION = "V6.1_FINAL_CLEAN"
st.set_page_config(page_title="ÙŠÙ‚ÙŠÙ† - Manadger Tech", page_icon="ğŸ¦…", layout="wide")
socket.setdefaulttimeout(10)
DB_FILE = "news_db_v6.json"

# ==========================================
# 1. Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙ†Ø¸ÙŠÙ (Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªØ­Ø¯ÙŠØ«)
# ==========================================
if "sys_version" not in st.session_state:
    st.session_state["sys_version"] = SYSTEM_VERSION
    st.cache_data.clear()

# ==========================================
# 2. Ø§Ù„Ù…ØµØ§Ø¯Ø±
# ==========================================
RSS_SOURCES = {
    "Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø´Ù…Ø§Ù„": {
        "Ø´Ù…Ø§Ù„ Ø¨ÙˆØ³Øª": "https://chamalpost.net/feed",
        "Ø¨Ø±ÙŠØ³ ØªØ·ÙˆØ§Ù†": "https://presstetouan.com/feed",
        "Ø·Ù†Ø¬Ø© 24": "https://tanja24.com/feed",
        "ØªØ·ÙˆØ§Ù† Ø¨Ø±ÙŠØ³": "https://tetouanpress.ma/feed",
        "ÙƒØ§Ø¨ 24": "https://cap24.tv/feed",
    },
    "Ø§Ù„ØµØ­Ø§ÙØ© Ø§Ù„Ù…ØºØ±Ø¨ÙŠØ©": {
        "Ù‡Ø³Ø¨Ø±ÙŠØ³": "https://www.hespress.com/feed",
        "Ø§Ù„Ø¹Ù…Ù‚": "https://al3omk.com/feed",
        "Ù…Ø¯Ø§Ø± 21": "https://madar21.com/feed",
        "ÙƒÙˆØ¯": "https://www.goud.ma/feed",
        "Ø§Ù„ØµØ¨Ø§Ø­": "https://assabah.ma/feed",
    },
    "ÙÙ† ÙˆÙ…Ø´Ø§Ù‡ÙŠØ±": {
        "Ù„Ø§Ù„Ø© Ù…ÙˆÙ„Ø§ØªÙŠ": "http://www.lallamoulati.ma/feed/",
        "Ø³Ù„Ø·Ø§Ù†Ø©": "https://soltana.ma/feed",
        "ØºØ§Ù„ÙŠØ©": "https://ghalia.ma/feed",
        "Ù‡Ø³Ø¨Ø±ÙŠØ³ ÙÙ†": "https://www.hespress.com/art-et-culture/feed",
        "Ø³ÙŠØ¯ØªÙŠ": "https://www.sayidaty.net/rss/3",
    },
    "Ø§Ù„Ø±ÙŠØ§Ø¶Ø©": {
        "Ø§Ù„Ø¨Ø·ÙˆÙ„Ø©": "https://www.elbotola.com/rss",
        "Ù‡Ø³Ø¨Ø±ÙŠØ³ Ø±ÙŠØ§Ø¶Ø©": "https://hesport.com/feed",
        "Ø§Ù„Ù…Ù†ØªØ®Ø¨": "https://almountakhab.com/rss",
        "Ù‡Ø§ÙŠ ÙƒÙˆØ±Ø©": "https://hihi2.com/feed",
    }
}

# ==========================================
# 3. CSS (Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø£ÙŠÙ‚ÙˆÙ†Ø§Øª ÙˆØ§Ù„Ø®Ø·ÙˆØ·)
# ==========================================
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;600;800&display=swap');
    
    /* ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø®Ø· Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØµÙˆØµ ÙÙ‚Ø· */
    html, body, h1, h2, h3, h4, h5, h6, p, div, span, label, button, input, textarea, .stMarkdown, .stText {
        font-family: 'Cairo', sans-serif;
        text-align: right;
    }
    
    /* Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø£ÙŠÙ‚ÙˆÙ†Ø§Øª Ù…Ù† Ø§Ù„ØªØ´ÙˆÙ‡ */
    i, .material-icons, [data-testid="stExpander"] svg, .st-emotion-cache-1pbqpg9 {
        font-family: initial !important;
    }

    /* Ø§Ù„ØªØ±ÙˆÙŠØ³Ø© */
    .brand-header {
        text-align: center;
        background: linear-gradient(180deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 25px;
        border-radius: 15px;
        border-bottom: 4px solid #1e3a8a;
        margin-bottom: 20px;
    }
    .main-title { color: #1e3a8a; font-size: 2.2rem; font-weight: 800; margin: 0; }
    .company-badge { background-color: #1e3a8a; color: white; padding: 4px 12px; border-radius: 20px; font-size: 0.85rem; display: inline-block; margin-bottom: 5px; }

    /* Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª */
    .stTabs [data-baseweb="tab-list"] { justify-content: center; background-color: #fff; border-radius: 10px; padding: 5px; }
    .stTabs [data-baseweb="tab"] { font-weight: 700; color: #495057; }
    .stTabs [aria-selected="true"] { color: #1e3a8a !important; border-bottom: 3px solid #1e3a8a !important; }

    /* Ø§Ù„Ø¨Ø·Ø§Ù‚Ø§Øª */
    .news-card {
        background: white; border: 1px solid #e2e8f0; border-right: 5px solid #3b82f6;
        border-radius: 10px; padding: 15px; margin-bottom: 10px; direction: rtl; text-align: right;
    }

    /* ØµÙ†Ø¯ÙˆÙ‚ Ø§Ù„Ù†ØªÙŠØ¬Ø© */
    .result-box {
        background: #f0fdf4; border: 1px solid #bbf7d0; border-right: 5px solid #22c55e;
        border-radius: 10px; padding: 20px; direction: rtl; margin-top: 15px;
    }

    /* Ø§Ù„Ø£Ø²Ø±Ø§Ø± */
    .stButton>button { width: 100%; border-radius: 8px; height: 50px; font-weight: 700; font-size: 16px; }

    #MainMenu {visibility: visible;} 
    footer {visibility: hidden;}
    
    /* Ù…Ø­Ø§Ø°Ø§Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª */
    .stTextInput input, .stTextArea textarea, .stSelectbox div[data-baseweb="select"] { 
        direction: rtl; text-align: right; 
    }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 4. Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ø®Ù„ÙÙŠ
# ==========================================
try:
    if "GROQ_API_KEY" in st.secrets:
        client = Groq(api_key=st.secrets["GROQ_API_KEY"])
    else: client = None
except: client = None

def fetch_feed_items(source_name, url):
    items = []
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/91.0.4472.124 Safari/537.36'}
    try:
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø°ÙƒÙŠØ©: Ù…Ø¨Ø§Ø´Ø± Ø«Ù… Ø¹Ø¨Ø± Requests
        d = feedparser.parse(url)
        if not d.entries:
            resp = requests.get(url, headers=headers, timeout=8)
            d = feedparser.parse(resp.content)
            
        for e in d.entries[:10]:
            items.append({
                "title": e.title, "link": e.link, "source": source_name,
                "published": e.get("published", "")
            })
    except: pass
    return items

def update_category_data(category):
    feeds = RSS_SOURCES[category]
    all_items = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(fetch_feed_items, src, url) for src, url in feeds.items()]
        for f in concurrent.futures.as_completed(futures):
            all_items.extend(f.result())
    return all_items

def load_db():
    if os.path.exists(DB_FILE):
        try:
            with open(DB_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data
        except: return {}
    return {}

def save_db(data):
    with open(DB_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False)

def get_text(url):
    try:
        d = trafilatura.fetch_url(url)
        return trafilatura.extract(d) if d else None
    except: return None

def rewrite(text, tone, instr):
    if not client: return "Ø®Ø·Ø£: Ø§Ù„Ù…ÙØªØ§Ø­ Ù…ÙÙ‚ÙˆØ¯"
    prompt = f"Ø£Ø¹Ø¯ ØµÙŠØ§ØºØ© Ù‡Ø°Ø§ Ø§Ù„Ø®Ø¨Ø± Ù„Ù€ Ù‡Ø§Ø´Ù…ÙŠ Ø¨Ø±ÙŠØ³. Ø§Ù„Ø£Ø³Ù„ÙˆØ¨: {tone}. Ù…Ù„Ø§Ø­Ø¸Ø§Øª: {instr}. Ø§Ù„Ù†Øµ: {text[:2500]}"
    try:
        res = client.chat.completions.create(
            messages=[{"role": "user", "content": prompt}],
            model="llama-3.3-70b-versatile", temperature=0.7
        )
        return res.choices[0].message.content
    except Exception as e: return str(e)

# ==========================================
# 5. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©
# ==========================================

st.markdown("""
<div class='brand-header'>
    <span class='company-badge'>Manadger Tech</span>
    <h1 class='main-title'>ÙˆÙƒÙŠÙ„ ÙŠÙ‚ÙŠÙ† AI</h1>
    <p style='color:#6c757d; margin-top:5px'>ØºØ±ÙØ© Ø§Ù„ØªØ­Ø±ÙŠØ± Ø§Ù„Ø°ÙƒÙŠØ©</p>
</div>
""", unsafe_allow_html=True)

db = load_db()

# Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª (Tabs)
cats = list(RSS_SOURCES.keys())
tabs = st.tabs(cats)

for i, cat_name in enumerate(cats):
    with tabs[i]:
        # Ù‡Ù„ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§ØªØŸ
        if "data" in db and cat_name in db["data"] and len(db["data"][cat_name]) > 0:
            news_list = db["data"][cat_name]
            
            # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙˆØ²Ø± Ø§Ù„ØªØ­Ø¯ÙŠØ«
            c1, c2 = st.columns([3, 1])
            with c1: st.success(f"Ù…ØªØ§Ø­ {len(news_list)} Ù…Ù‚Ø§Ù„")
            with c2:
                if st.button("ğŸ”„ ØªØ­Ø¯ÙŠØ«", key=f"up_{i}"):
                    with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ø¯ÙŠØ«..."):
                        if "data" not in db: db["data"] = {}
                        db["data"][cat_name] = update_category_data(cat_name)
                        save_db(db)
                    st.rerun()

            # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ù‚Ø§Ù„
            opts = [f"{n['source']} | {n['title']}" for n in news_list]
            idx = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ù…Ù‚Ø§Ù„:", range(len(opts)), format_func=lambda x: opts[x], key=f"sel_{i}")

            # Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
            with st.expander("âš™ï¸ Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØµÙŠØ§ØºØ©"):
                tone = st.select_slider("Ø§Ù„Ø£Ø³Ù„ÙˆØ¨", ["Ø±Ø³Ù…ÙŠ", "ØªØ­Ù„ÙŠÙ„ÙŠ", "ØªÙØ§Ø¹Ù„ÙŠ"], key=f"tn_{i}")
                ins = st.text_input("ØªÙˆØ¬ÙŠÙ‡Ø§Øª", key=f"in_{i}")

            # Ø§Ù„ØªÙ†ÙÙŠØ°
            if st.button("âœ¨ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ù…Ù‚Ø§Ù„", type="primary", key=f"go_{i}"):
                sel = news_list[idx]
                with st.status("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¹Ù…Ù„...", expanded=True):
                    st.write("ğŸ“¥ Ø³Ø­Ø¨ Ø§Ù„Ù†Øµ...")
                    txt = get_text(sel['link'])
                    if txt:
                        st.write("ğŸ§  Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙƒØªØ¨...")
                        res = rewrite(txt, tone, ins)
                        st.success("ØªÙ…!")
                        st.markdown(f"<div class='result-box'>{res}</div>", unsafe_allow_html=True)
                        st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Øµ", res, "article.txt", key=f"dl_{i}")
                    else: st.error("Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ù…Ø­Ù…ÙŠ")
        else:
            # Ø­Ø§Ù„Ø© Ø§Ù„Ù‚Ø³Ù… Ø§Ù„ÙØ§Ø±Øº
            st.warning(f"Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù‚Ø§Ù„Ø§Øª Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ {cat_name}")
            if st.button(f"ğŸ“¥ Ø¬Ù„Ø¨ Ù…Ù‚Ø§Ù„Ø§Øª {cat_name} Ø§Ù„Ø¢Ù†", type="primary", key=f"init_{i}"):
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù…ØµØ§Ø¯Ø±..."):
                    if "data" not in db: db["data"] = {}
                    db["data"][cat_name] = update_category_data(cat_name)
                    save_db(db)
                st.rerun()

# End of file
